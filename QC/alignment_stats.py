#! /usr/bin/env python2.7

from optparse import OptionParser
import os
import sys
import re
import json
import subprocess
import glob
from tools import *

class Align_Stats:
	def __init__(self, json_file, debug=False):
		self.debug = debug
		self.json_file = json_file
		self.jsonData = json.load(open(json_file))
		self.main()

	# get the stats and store them in the json file
	def main(self):
		if 'run_data' not in self.jsonData:
			self.jsonData['run_data'] = {}
		# if the stats have already been gathered, then skip this step.
		if 'median_read_length' not in self.jsonData['run_data']: 
			self.jsonData['run_data']['median_read_length'] = ''
		if 'mean_read_length' not in self.jsonData['run_data']:
			self.jsonData['run_data']['mean_read_length'] = ''
		if 'aligned_bases' not in self.jsonData['run_data']:
			self.jsonData['run_data']['aligned_bases'] = ''
		if 'aq20_bases' not in self.jsonData['run_data']:
			self.jsonData['run_data']['aq20_bases'] = ''
		if self.jsonData['run_data']['median_read_length'] == "" or self.jsonData['run_data']['mean_read_length'] == "" or self.jsonData['run_data']['aligned_bases'] == "" or self.jsonData['run_data']['aq20_bases'] == "":
			#print "Gathering 'median_read_length'"
			bam_file = "%s/%s"%(self.jsonData['run_folder'], self.jsonData['analysis']['files'][0])
			output_folder = "%s/Analysis_Files"%self.jsonData['run_folder']
			# if the Analysis_Files dir doesn't exist, make it
			if not os.path.isdir(output_folder):
				os.mkdir(output_folder)
			self.calcStatsFromBam(bam_file, output_folder)
			print 'aq20_bases: %s, aligned_bases: %s, mean_read_length: %s, median_read_length: %s'%(self.jsonData['run_data']['aq20_bases'], self.jsonData['run_data']['aligned_bases'], self.jsonData['run_data']['mean_read_length'], self.jsonData['run_data']['median_read_length'])
			#write new json file
			with open(self.json_file, 'w') as newJobFile:
				json.dump(self.jsonData, newJobFile, sort_keys=True, indent=4)
	
	# @param align_file the alignment file ouput by running "ionstats alignment -i run.bam -o run.alignment"
	# @param output_dir the folder where the stats json files should be
	def getStatsFromAlignFile(self, align_file, output_dir):
		# get the AQ20 and aligned bases from the aligninfos.json file
		if os.path.isfile(align_file):
			align_json = json.load(open(align_file))
			if self.debug:
				print "%s json data for align_json['full']: %s"%(align_file, align_json['full'])
			self.jsonData['run_data']['median_read_length'] = self.getMedianFromHisto(align_json['full']['read_length_histogram'], align_json['full']['num_reads'])
			self.jsonData['run_data']['mean_read_length'] = align_json['full']['mean_read_length']
			self.jsonData['run_data']['aq20_bases'] = align_json['AQ20']['num_bases']
			self.jsonData['run_data']['aligned_bases'] = align_json['aligned']['num_bases']
		# otherwise look for the serialized*.json file created from an archived run
		elif glob.glob("%s/serialized*.json"%output_dir):
			serialized_file = glob.glob("%s/serialized*.json"%output_dir)[0]
			serialized_json = json.load(open(serialized_file))
			# now find the AQ20 and total aligned bases
			for dictionary in serialized_json:
				if 'model' in dictionary and dictionary['model'] == "rundb.libmetrics":
					# the aq20 and aligned bases are here
					self.jsonData['run_data']['aq20_bases'] = dictionary['fields']["q20_mapped_bases"]
					self.jsonData['run_data']['aligned_bases'] = dictionary['fields']["total_mapped_target_bases"]
				elif 'model' in dictionary and dictionary['model'] == "rundb.qualitymetrics":
					self.jsonData['run_data']['mean_read_length'] = dictionary['fields']["q0_mean_read_length"]

	# Calculates the mean read length from a histogram of read lengths.
	# In a histogram, each positino in the graph (or list here) is a read length, and the value at each position is the number of reads that have that length
	# Therefore to calculate the mean, simply sum the (number of reads at a given length * the given length), then divide by total number of reads 
	# @param histogram a list containing the histogram generated by ionstats or gathered from the proton or pgm.
	# @param total_num_reads the total number of reads in the histogram.
	# @returns the mean read length
	def getMeanFromHisto(self, histogram, total_num_reads):
		sum_reads = 0
		for i in xrange(len(histogram)):
			sum_reads += (histogram[i]*i)
		# sum the reads to get the mean.
		mean = sum_reads / float(total_num_reads)
		return mean

	# Calculates the medain read length from a histogram of read lengths.
	# In a histogram, each positino in the graph (or list here) is a read length, and the value at each position is the number of reads that have that length
	# Therefore to calculate the median, simply add the total number of reads until you hit 50% of the reads, and there's your median.
	# @param histogram a list containing the histogram generated by ionstats or gathered from the proton or pgm.
	# @param total_num_reads the total number of reads in the histogram.
	# @returns the median read length
	def getMedianFromHisto(self, histogram, total_num_reads):
		med = 0
		num_reads = 0
		for i in xrange(len(histogram)):
			num_reads += (histogram[i])
			if num_reads > (total_num_reads/2):
				med = i 
				break
		return med

	# runs ionstats to generate the statistics on the alignment file, particularly the read length histogram
	# @param bam the bam file on which to calculate the median read length
	# @returns the medain read length of the bam file
	def calcStatsFromBam(self, bam, output_dir):
		print "%s   - Beginning to gather the ionstats"%bam
		align_file = "%s/ionstats_alignment.json"%output_dir
		self.getStatsFromAlignFile(align_file, output_dir)
		# if the bam file is not found, there's nothing we can do.
		if not os.path.isfile(bam):
			print "%s  - bam file not found. cannot gather stats"%bam
		else:
			# if the stats were not gathered, then try again.
			if self.jsonData['run_data']['median_read_length'] == "" or self.jsonData['run_data']['mean_read_length'] == "" or self.jsonData['run_data']['aligned_bases'] == "" or self.jsonData['run_data']['aq20_bases'] == "":
				command = "ionstats alignment -i %s -o %s "%(bam, align_file)
				# run the command and check the output status
				runCommandLine(command)
				self.getStatsFromAlignFile(align_file, output_dir)
				# cleanup the ionstats_error_summary.h5 file here as well.
				if os.path.isfile('ionstats_error_summary.h5'):
					os.remove('ionstats_error_summary.h5')
				#print " Median Read Length: %s.  Mean Read Length: %s"%(med, mean)
				#if self.debug:
				#	print "Not removing %s"%align_file
				#else:
				#	os.remove(align_file)
			# if ionstats wasn't available or didn't work, then use samtools to calculate the read lengths
			if self.jsonData['run_data']['median_read_length'] == "" or self.jsonData['run_data']['mean_read_length'] == "" or self.jsonData['run_data']['aligned_bases'] == "":
				print "	ionstats failed on %s :("%bam
				status = 0
				reads_file = "%s/rawlib.reads"%output_dir
				# if the reads file has not already been generated, then generate it here
				if not os.path.isfile(reads_file):
					# Use samtools and awk to write a file with all of the read lengths
					command = "samtools view %s | awk '{ print length($10) }' > %s"%(bam, reads_file)
					print "	Trying %s"%command
					status = runCommandLine(command)
					if status != 0:
						print "samtools failed on %s :("%bam
						#os.remove(reads_file)
	
				if status == 0:
					# calculate the median read length
					command = "sort -n %s | awk '{ count[NR] = $1; } END { if (NR %% 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) /2.0; }}'"%reads_file
					self.jsonData['run_data']['median_read_length'] = runCommandLine(command, get_output=True)
		
					# calculate the mean read length
					command = "awk '{ sum += $1 } END { if (NR > 0) print sum / NR }' %s"%reads_file
					self.jsonData['run_data']['mean_read_length'] = runCommandLine(command, get_output=True)
		
					# calculate the aligned_bases
					# TODO the -F 4 option needs to be used to get only the aligned reads and therefore aligned bases.
					#command = "awk '{ sum += $1 } END { print sum }' %s"%reads_file
					#self.jsonData['run_data']['aligned_bases'] = runCommandLine(command, get_output=True)
					print " Median Read Length: %s.  Mean Read Length: %s"%(self.jsonData['run_data']['median_read_length'], self.jsonData['run_data']['mean_read_length'])

					# I couldn't figure out how to calculate the aq20_bases... I tried using the -q 20 options with samtools, but that didn't work...
					# the reads_file is about 530 Mb so just remove it.
					os.remove(reads_file)

if __name__ == '__main__':

	# set up the option parser
	parser = OptionParser()
	
	# add the options to parse
	#parser.add_option('-i', '--input', dest='input', help='The input bam or alignment file of which you wish to gather stats. currently on the median read length is reported. ')
	#parser.add_option('-o', '--output', dest='output', help='The output directory. If no output dir is specified, the files will be made in the same dir as the bam file.')
	parser.add_option('-d', '--debug', dest='debug', action='store_true', help='Will not delete the bam.alignment file generated and will print more info to the screen.')
	parser.add_option('-j', '--json', dest='json', help='The run json file')

	(options, args) = parser.parse_args()

	if not options.json:
		print "USAGE ERROR-- --json is required"
		parser.print_help()
		sys.exit(1)
	if not os.path.isfile(options.json):
		print "USAGE ERROR-- %s not found"%(options.json)
		parser.print_help()
		sys.exit(1)

	align_stats = Align_Stats(options.json, options.debug)

	#print "	median read length: %s" %align_stats.median_read_length
	#print "	mean read length: %s" %align_stats.mean_read_length
	#print "	aligned_bases: %s" %align_stats.aligned_bases
	#print "	aq20_bases: %s" %align_stats.aq20_bases

